[project]
authors = [{ name = "Modular Inc", email = "hello@modular.com" }]
name = "code-execution-sandbox-agent-with-e2b"
requires-python = ">=3.10,<3.13"
version = "0.0.0"
dependencies = [
    "python-dotenv>=1.0.1,<2",
    "rich>=13.9.4,<15",
]

[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.pixi.project]
channels = [
    "https://conda.modular.com/max-nightly",
    "conda-forge",
]
platforms = ["linux-64", "linux-aarch64", "osx-arm64"]

[tool.pixi.pypi-dependencies]
code_execution_sandbox_agent_with_e2b = { path = ".", editable = true }

[tool.pixi.dependencies]
python = ">=3.10,<3.13"

# Feature for MAX server (needs modular package with newer protobuf)
[tool.pixi.feature.server.dependencies]
modular = ">=25.5.0.dev2025070905,<26"

[tool.pixi.feature.server.pypi-dependencies]
openai = ">=1.65.1,<2"

# Feature for e2b agent (needs older protobuf)
[tool.pixi.feature.agent.pypi-dependencies]
openai = ">=1.65.1,<2"
e2b-code-interpreter = ">=1.0.5,<2"

# Define environments
[tool.pixi.environments]
server = ["server"]
agent = ["agent"]

[tool.pixi.tasks]
hello = "python hello.py"
tests = "echo 'test passed'"
server = "MAX_SERVE_PORT=8010 max serve --model-path modularai/Llama-3.1-8B-Instruct-GGUF --enable-structured-output"
agent = "python agent.py"
