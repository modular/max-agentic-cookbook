[project]
authors = [{ name = "Modular Inc", email = "hello@modular.com" }]
name = "code-execution-sandbox-agent-with-e2b"
requires-python = ">=3.10,<3.13"
version = "0.0.0"
dependencies = [ "openai>=1.65.1,<2", "e2b-code-interpreter>=1.0.5,<2", "python-dotenv>=1.0.1,<2", "rich>=13.9.4,<14"]

[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.pixi.project]
channels = ["https://conda.modular.com/max-nightly", "https://conda.modular.com/max", "https://repo.prefix.dev/modular-community", "conda-forge"]
platforms = ["linux-64"]

[tool.pixi.pypi-dependencies]
code_execution_sandbox_agent_with_e2b = { path = ".", editable = true }

[tool.pixi.tasks]
server = "magic global install max-pipelines && magic global update max-pipelines || true; MAX_SERVE_PORT=8010 max-pipelines serve --model-path modularai/Llama-3.1-8B-Instruct-GGUF --enable-structured-output"
hello = "magic run python hello.py"
agent = "magic run python agent.py"
