version: 1.0
long_title: "Learn How to Run Offline Inference with MAX Pipelines"
short_title: "Offline inference with MAX"
author: "Bill Welense"
author_image: "author/billw.jpg"
author_url: "https://www.linkedin.com/in/welense/"
github_repo: "https://github.com/modular/max-recipes/tree/main/max-offline-inference"
date: "13-02-2025"
difficulty: "beginner"
tags:
  - max-pipelines
  - llama3
  - archived

tasks:
  - magic run app
