llm-server: MAX_SERVE_PORT=8010 max serve --model-path meta-llama/Llama-3.2-11B-Vision-Instruct --max-length 2048 --max-batch-size 1
qdrant-server: docker run -p 6333:6333 -p 6334:6334 -v "$(pwd)/qdrant_storage:/qdrant/storage:z" docker.io/qdrant/qdrant
app: pixi run agent
