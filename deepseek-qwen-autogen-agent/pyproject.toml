[project]
authors = [{ name = "Modular Inc", email = "hello@modular.com" }]
dependencies = ["autogen-agentchat==0.4.7", "autogen-ext[openai]==0.4.7", "rich>=13.9.4,<14", "python-chess>=1.999,<2", "tenacity>=9.0.0,<10", "requests>=2.32.3,<3"]
name = "deepseek-qwen-autogen-agent"
requires-python = ">=3.10,<3.13"
version = "0.0.0"

[system-requirements]
cuda = "12.5"

[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.pixi.project]
channels = ["https://conda.modular.com/max-nightly", "https://conda.modular.com/max", "https://repo.prefix.dev/modular-community", "conda-forge"]
platforms = ["linux-64"]

[tool.pixi.pypi-dependencies]
deepseek_qwen_autogen_agent = { path = ".", editable = true }

[tool.pixi.tasks]
server = "(magic global install max-pipelines && magic global update max-pipelines) || true; MAX_SERVE_PORT=8010 MAX_SERVE_HOST=0.0.0.0 max-pipelines serve --huggingface-repo-id=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --max-length 16384 --max-batch-size 1"
chat_agent = "magic run python chat_agent.py"
screenplay_agents = "magic run python screenplay_agents.py"
